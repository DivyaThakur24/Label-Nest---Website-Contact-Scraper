{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Approach / Logic**\n",
        "\n",
        "1. **Input:** Two company website URLs (you can use any, e.g., https://www.python.org and https://www.djangoproject.com).\n",
        "\n",
        "2. **Fetch** the HTML using requests.\n",
        "\n",
        "3. **Parse** the content using BeautifulSoup.\n",
        "\n",
        "4. **Extract** emails, phone numbers, and links using regular expressions (regex).\n",
        "\n",
        "5. **Clean and validate** data (check for duplicates or invalid formats).\n",
        "\n",
        "6. **Save output** to CSV using pandas."
      ],
      "metadata": {
        "id": "19KwiXeHsjWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Website Contact Scraper**"
      ],
      "metadata": {
        "id": "LPuPYnnwtAQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qZ750PHisW7G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- CONFIGURATION ----------\n",
        "websites = [\n",
        "    \"https://www.pw.live\",\n",
        "    \"https://www.labelnest.in\"\n",
        "]"
      ],
      "metadata": {
        "id": "4ad0it_dtGz6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- REGEX PATTERNS ----------\n",
        "# Email pattern\n",
        "email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "\n",
        "# Phone pattern (includes normal + toll-free like 1800/1860)\n",
        "phone_pattern = r\"(\\+?\\d[\\d\\s\\-().]{7,}\\d|1800[\\s\\-]?\\d{3}[\\s\\-]?\\d{4}|1860[\\s\\-]?\\d{3}[\\s\\-]?\\d{4})\"\n",
        "\n",
        "# Validation patterns\n",
        "valid_email_pattern = re.compile(r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\")\n",
        "valid_phone_pattern = re.compile(r\"^(\\+?\\d[\\d\\s\\-().]{7,}\\d|1800[\\s\\-]?\\d{3}[\\s\\-]?\\d{4}|1860[\\s\\-]?\\d{3}[\\s\\-]?\\d{4})$\")"
      ],
      "metadata": {
        "id": "GttLIQUptG-l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- FUNCTIONS ----------\n",
        "def is_valid_email(email):\n",
        "    return bool(valid_email_pattern.match(email))\n",
        "\n",
        "def is_valid_phone(phone):\n",
        "    return bool(valid_phone_pattern.match(phone))"
      ],
      "metadata": {
        "id": "NSr8mutCtHGe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_links(links):\n",
        "    \"\"\"Normalize and remove duplicate links.\"\"\"\n",
        "    cleaned = []\n",
        "    for link in links:\n",
        "        # Strip fragments (#), query params, trailing slashes\n",
        "        link = re.sub(r'#.*$', '', link)\n",
        "        link = re.sub(r'\\?.*$', '', link)\n",
        "        link = link.rstrip('/')\n",
        "        if link not in cleaned:\n",
        "            cleaned.append(link)\n",
        "    return cleaned"
      ],
      "metadata": {
        "id": "-18R8chBtHJ8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_contact_info(url):\n",
        "    notes = \"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        text = soup.get_text(\" \", strip=True)\n",
        "        links = [a['href'] for a in soup.find_all('a', href=True)]\n",
        "\n",
        "        # Extract contact info\n",
        "        emails = list(set(re.findall(email_pattern, text)))\n",
        "        phones = list(set(re.findall(phone_pattern, text)))\n",
        "\n",
        "        # Validate\n",
        "        valid_emails = [e for e in emails if is_valid_email(e)]\n",
        "        valid_phones = [p for p in phones if is_valid_phone(p)]\n",
        "\n",
        "        # Find and clean contact page links\n",
        "        contact_pages = [link for link in links if 'contact' in link.lower()]\n",
        "        contact_pages = clean_links(contact_pages)\n",
        "\n",
        "        if not valid_emails and not valid_phones:\n",
        "            notes = \"No valid contact info found on main page\"\n",
        "\n",
        "        return {\n",
        "            \"Website\": url,\n",
        "            \"Email\": \", \".join(valid_emails) if valid_emails else \"-\",\n",
        "            \"Phone\": \", \".join(valid_phones) if valid_phones else \"-\",\n",
        "            \"Page Found\": \", \".join(contact_pages) if contact_pages else url,\n",
        "            \"Notes\": notes\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"Website\": url,\n",
        "            \"Email\": \"-\",\n",
        "            \"Phone\": \"-\",\n",
        "            \"Page Found\": \"-\",\n",
        "            \"Notes\": f\"Error: {e}\"\n",
        "        }"
      ],
      "metadata": {
        "id": "16qRmfgDtHNg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- MAIN SCRIPT ----------\n",
        "print(\"üîç Starting Website Contact Scraper...\\n\")\n",
        "\n",
        "results = [scrape_contact_info(site) for site in websites]\n",
        "df = pd.DataFrame(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Y-VPbZtHQ5",
        "outputId": "d7f42cbb-0502-4abd-96e0-278248e3b3a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Starting Website Contact Scraper...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates based on Email + Phone\n",
        "df.drop_duplicates(subset=[\"Email\", \"Phone\"], inplace=True)"
      ],
      "metadata": {
        "id": "CD14azHmtHUH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "output_file = \"contacts.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"‚úÖ Scraping Complete!\")\n",
        "print(\"üìÅ Data saved to:\", output_file)\n",
        "print(\"\\nüìä Extracted Contact Information:\\n\")\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o08WP7OtHXQ",
        "outputId": "7bb2e91d-b024-45b1-8bb8-d2bd8ca72adb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Scraping Complete!\n",
            "üìÅ Data saved to: contacts.csv\n",
            "\n",
            "üìä Extracted Contact Information:\n",
            "\n",
            "                 Website                Email                   Phone                          Page Found Notes\n",
            "     https://www.pw.live                    - 08448982616 08448982616      https://www.pw.live/contact-us      \n",
            "https://www.labelnest.in contact@labelnest.in          +91 9731474655 https://www.labelnest.in/contact-us      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9ibrnWttHa0"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}